{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50c171fc",
   "metadata": {},
   "source": [
    "### Imported libreries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37d3ec8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Model preparating \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "# Modeling\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "# Warning manage\n",
    "\n",
    "import warnings\n",
    "from sklearn.exceptions import DataConversionWarning, ConvergenceWarning\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=DataConversionWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "warnings.filterwarnings(\"ignore\", message=\"Inconsistent values: penalty=l1 with l1_ratio=0.0\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f129740b",
   "metadata": {},
   "source": [
    "### Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "943ccc74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>package_name</th>\n",
       "      <th>review</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>com.facebook.katana</td>\n",
       "      <td>privacy at least put some option appear offli...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>com.facebook.katana</td>\n",
       "      <td>messenger issues ever since the last update, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>com.facebook.katana</td>\n",
       "      <td>profile any time my wife or anybody has more ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>com.facebook.katana</td>\n",
       "      <td>the new features suck for those of us who don...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>com.facebook.katana</td>\n",
       "      <td>forced reload on uploading pic on replying co...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          package_name                                             review  \\\n",
       "0  com.facebook.katana   privacy at least put some option appear offli...   \n",
       "1  com.facebook.katana   messenger issues ever since the last update, ...   \n",
       "2  com.facebook.katana   profile any time my wife or anybody has more ...   \n",
       "3  com.facebook.katana   the new features suck for those of us who don...   \n",
       "4  com.facebook.katana   forced reload on uploading pic on replying co...   \n",
       "\n",
       "   polarity  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"https://raw.githubusercontent.com/4GeeksAcademy/naive-bayes-project-tutorial/main/playstore_reviews.csv\")\n",
    "\n",
    "df.to_excel(\"../data/raw/df.xlsx\", index = False)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c23aea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dimensions of this dataset are 891 rows and 3 columns\n"
     ]
    }
   ],
   "source": [
    "rows, columns = df.shape\n",
    "print(f\"The dimensions of this dataset are {rows} rows and {columns} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed3d0713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dimensions of this dataset are 891 rows and 2 columns\n"
     ]
    }
   ],
   "source": [
    "df.drop([\"package_name\"], axis= 1, inplace= True)\n",
    "rows, columns = df.shape\n",
    "df[\"review\"] = df[\"review\"].str.strip().str.lower()\n",
    "print(f\"The dimensions of this dataset are {rows} rows and {columns} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fad3b943",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>privacy at least put some option appear offlin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>messenger issues ever since the last update, i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>profile any time my wife or anybody has more t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the new features suck for those of us who don'...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>forced reload on uploading pic on replying com...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  polarity\n",
       "0  privacy at least put some option appear offlin...         0\n",
       "1  messenger issues ever since the last update, i...         0\n",
       "2  profile any time my wife or anybody has more t...         0\n",
       "3  the new features suck for those of us who don'...         0\n",
       "4  forced reload on uploading pic on replying com...         0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ba1763",
   "metadata": {},
   "source": [
    "### Model preparating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6592588b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "873    such an awesome game love it a really fun game...\n",
       "828                    dami xa hajur harule ni hernu hai\n",
       "99     updated version is down not able to sent conne...\n",
       "523    rubbish the amount of memory it gives for free...\n",
       "132    every time i play the moon struck game, it doe...\n",
       "Name: review, dtype: str"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = df[\"review\"]\n",
    "y = df[\"polarity\"]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 17)\n",
    "\n",
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "20946f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_model = CountVectorizer(stop_words = \"english\")\n",
    "X_train = vec_model.fit_transform(x_train).toarray()\n",
    "X_test = vec_model.transform(x_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e18d4a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== MODEL COMPARISON ======\n",
      "           Model  Train_Accuracy  Test_Accuracy  Train_Precision  \\\n",
      "1  MultinomialNB        0.963483       0.754190         0.977169   \n",
      "0     GaussianNB        0.988764       0.726257         0.967078   \n",
      "2    BernoulliNB        0.915730       0.709497         0.983425   \n",
      "\n",
      "   Test_Precision  Train_Recall  Test_Recall  Train_F1   Test_F1  \n",
      "1        0.791667      0.910638     0.527778  0.942731  0.633333  \n",
      "0        0.767442      1.000000     0.458333  0.983264  0.573913  \n",
      "2        0.794118      0.757447     0.375000  0.855769  0.509434  \n",
      "\n",
      "====== BEST MODEL BASED ON TEST F1 ======\n",
      "Model              MultinomialNB\n",
      "Train_Accuracy          0.963483\n",
      "Test_Accuracy            0.75419\n",
      "Train_Precision         0.977169\n",
      "Test_Precision          0.791667\n",
      "Train_Recall            0.910638\n",
      "Test_Recall             0.527778\n",
      "Train_F1                0.942731\n",
      "Test_F1                 0.633333\n",
      "Name: 1, dtype: object\n",
      "\n",
      "====== FINAL CONFUSION MATRIX ======\n",
      "[[97 10]\n",
      " [34 38]]\n",
      "\n",
      "====== FINAL CLASSIFICATION REPORT ======\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.91      0.82       107\n",
      "           1       0.79      0.53      0.63        72\n",
      "\n",
      "    accuracy                           0.75       179\n",
      "   macro avg       0.77      0.72      0.72       179\n",
      "weighted avg       0.76      0.75      0.74       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    \"GaussianNB\": GaussianNB(),\n",
    "    \"MultinomialNB\": MultinomialNB(),\n",
    "    \"BernoulliNB\": BernoulliNB()\n",
    "}\n",
    "\n",
    "def build_and_evaluate(models):\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for name, model in models.items():\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        y_pred_train = model.predict(X_train)\n",
    "        y_pred_test = model.predict(X_test)\n",
    "\n",
    "        results.append({\n",
    "            \"Model\": name,\n",
    "\n",
    "            \"Train_Accuracy\": accuracy_score(y_train, y_pred_train),\n",
    "            \"Test_Accuracy\": accuracy_score(y_test, y_pred_test),\n",
    "\n",
    "            \"Train_Precision\": precision_score(y_train, y_pred_train),\n",
    "            \"Test_Precision\": precision_score(y_test, y_pred_test),\n",
    "\n",
    "            \"Train_Recall\": recall_score(y_train, y_pred_train),\n",
    "            \"Test_Recall\": recall_score(y_test, y_pred_test),\n",
    "\n",
    "            \"Train_F1\": f1_score(y_train, y_pred_train),\n",
    "            \"Test_F1\": f1_score(y_test, y_pred_test)\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Results comparison\n",
    "\n",
    "df_results = build_and_evaluate(models)\n",
    "df_results = df_results.sort_values(by=\"Test_F1\", ascending=False)\n",
    "\n",
    "print(\"====== MODEL COMPARISON ======\")\n",
    "print(df_results)\n",
    "\n",
    "# Best model\n",
    "\n",
    "best_model_row = df_results.iloc[0]\n",
    "best_model_name = best_model_row[\"Model\"]\n",
    "best_model = models[best_model_name]\n",
    "\n",
    "print(\"\\n====== BEST MODEL BASED ON TEST F1 ======\")\n",
    "print(best_model_row)\n",
    "\n",
    "# Final evaluation\n",
    "\n",
    "best_model.fit(X_train, y_train)\n",
    "y_pred_final = best_model.predict(X_test)\n",
    "\n",
    "print(\"\\n====== FINAL CONFUSION MATRIX ======\")\n",
    "print(confusion_matrix(y_test, y_pred_final))\n",
    "\n",
    "print(\"\\n====== FINAL CLASSIFICATION REPORT ======\")\n",
    "print(classification_report(y_test, y_pred_final))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a095ca",
   "metadata": {},
   "source": [
    "### Hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c02cd03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"alpha\": np.linspace(0.001, 1.0, 100),\n",
    "    \"fit_prior\": [True, False]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50397ee1",
   "metadata": {},
   "source": [
    "#### Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "07f3b05b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================ FINAL CONCLUSION ================\n",
      "Best params: {'fit_prior': False, 'alpha': np.float64(0.09181818181818183)}\n",
      "The best model is:  MultinomialNB(alpha=np.float64(0.09181818181818183), fit_prior=False)\n",
      "The score for this model is:  0.736465731213953\n"
     ]
    }
   ],
   "source": [
    "random_search = RandomizedSearchCV(\n",
    "    MultinomialNB(),\n",
    "    params,\n",
    "    scoring=\"f1\",\n",
    "    cv=5,\n",
    "    n_iter=50,\n",
    "    random_state=10,\n",
    "    n_jobs=-1\n",
    ")\n",
    "random_search.fit(X_train, y_train) # Entreno el optimizador con el dataset GANADOR\n",
    "\n",
    "print(\"\\n================ FINAL CONCLUSION ================\")\n",
    "print(\"Best params:\", random_search.best_params_)\n",
    "best_model_random = random_search.best_estimator_\n",
    "print(\"The best model is: \", best_model_random)\n",
    "print(\"The score for this model is: \", random_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e1b93b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== TRAIN METRICS ==========\n",
      "Accuracy: 0.9902\n",
      "F1-score: 0.9851\n",
      "Precision: 0.9831\n",
      "Recall: 0.9872\n",
      "Confusion Matrix:\n",
      " [[473   4]\n",
      " [  3 232]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       477\n",
      "           1       0.98      0.99      0.99       235\n",
      "\n",
      "    accuracy                           0.99       712\n",
      "   macro avg       0.99      0.99      0.99       712\n",
      "weighted avg       0.99      0.99      0.99       712\n",
      "\n",
      "\n",
      "========== TEST METRICS ==========\n",
      "Accuracy: 0.7654\n",
      "F1-score: 0.6719\n",
      "Precision: 0.7679\n",
      "Recall: 0.5972\n",
      "Confusion Matrix:\n",
      " [[94 13]\n",
      " [29 43]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.88      0.82       107\n",
      "           1       0.77      0.60      0.67        72\n",
      "\n",
      "    accuracy                           0.77       179\n",
      "   macro avg       0.77      0.74      0.74       179\n",
      "weighted avg       0.77      0.77      0.76       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(model, X_train, y_train, X_test, y_test):\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    datasets = {\n",
    "        \"TRAIN\": (X_train, y_train),\n",
    "        \"TEST\": (X_test, y_test)\n",
    "    }\n",
    "\n",
    "    for name, (X, y) in datasets.items():\n",
    "        y_pred = model.predict(X)\n",
    "        print(f\"\\n========== {name} METRICS ==========\")\n",
    "        print(f\"Accuracy: {accuracy_score(y, y_pred):.4f}\")\n",
    "        print(f\"F1-score: {f1_score(y, y_pred):.4f}\")\n",
    "        print(f\"Precision: {precision_score(y, y_pred):.4f}\")\n",
    "        print(f\"Recall: {recall_score(y, y_pred):.4f}\")\n",
    "        print(\"Confusion Matrix:\\n\", confusion_matrix(y, y_pred))\n",
    "        print(\"\\nClassification Report:\\n\", classification_report(y, y_pred))\n",
    "\n",
    "evaluate_model(best_model_random, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5c43e8",
   "metadata": {},
   "source": [
    "**Following hyperparameter optimization of the Multinomial Naive Bayes model, improved performance was observed across the test set. Specifically, the F1 score increased by approximately 6%, driven by a recall increase of over 13%, indicating the model's improved ability to correctly identify positive feedback. Although accuracy decreased slightly, the overall balance between accuracy and recall improved, justifying the optimization process.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
